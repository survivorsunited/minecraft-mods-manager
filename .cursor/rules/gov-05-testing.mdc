---
description: 
globs: 
alwaysApply: true
---
# Governance: Universal Testing Principles

## ⚠️ CRITICAL: TEST-FIRST MANDATORY RULE ⚠️

**HIGHEST PRIORITY**: When given any task, bug fix, or feature request:
1. **STOP** - Do not write any code yet
2. **WRITE TEST FIRST** - Create a test that validates the issue/requirement
3. **VERIFY TEST FAILS** - Confirm the test catches the problem
4. **THEN** write code to make the test pass

**This rule applies to ALL work - no exceptions.**

## Core Testing Philosophy

### MANDATORY: Test-Driven Development (TDD) - HIGHEST PRIORITY

**CRITICAL RULE**: Tests MUST be written FIRST before any code changes. This is the HIGHEST PRIORITY workflow requirement.

**FORBIDDEN:**
- ❌ Writing code before writing tests
- ❌ Making code changes without a test to validate the issue
- ❌ Skipping test creation "to save time"
- ❌ Writing tests after code is "done"

**REQUIRED:**
- ✅ Write test FIRST to validate the issue/problem
- ✅ Test must FAIL initially (red phase)
- ✅ Write minimal code to make test pass (green phase)
- ✅ Refactor if needed (refactor phase)
- ✅ Test must be isolated and use clean database

**TDD Workflow (MANDATORY):**
1. **RED**: Write failing test that validates the issue/requirement
2. **GREEN**: Write minimal code to make test pass
3. **REFACTOR**: Improve code while keeping tests passing
4. **REPEAT**: Continue cycle for each new requirement

**Test-First Checklist:**
- [ ] Test written before any code changes
- [ ] Test validates the specific issue/requirement
- [ ] Test uses isolated database (clean state)
- [ ] Test fails initially (proves it catches the issue)
- [ ] Code written to make test pass
- [ ] All tests pass after implementation

### Test-Driven Development (TDD) Details
1. **E2E Test First**: Create end-to-end test that reflects real user flow
2. **Minimal Implementation**: Implement only what makes the E2E test pass
3. **Unit Test Coverage**: Add unit tests for reusable logic
4. **Test Maintenance**: Update existing tests for changed behavior

### Testing Hierarchy
- **E2E Tests**: Validate complete user workflows
- **Integration Tests**: Test component interactions
- **Unit Tests**: Test individual functions and methods
- **Regression Tests**: Ensure existing functionality remains intact

## Test Organization

### Test Structure
- Use isolated test directories to prevent interference
- Follow consistent naming conventions
- Organize tests by functionality and scope
- Maintain clear test descriptions

### Test Execution
- Run tests in isolation to prevent side effects
- Use cleanup procedures to maintain clean state
- Execute tests in predictable order
- Capture and report test results consistently

### Test Artifacts
- Generate comprehensive test reports
- Log test execution details
- Preserve test outputs for analysis
- Clean up test artifacts after completion

## Quality Standards

### Test Reliability
- Tests must be deterministic and repeatable
- Avoid flaky tests and race conditions
- Use proper setup and teardown procedures
- Handle external dependencies appropriately

### Test Coverage
- Aim for comprehensive coverage of critical paths
- Focus on business logic and edge cases
- Test error conditions and failure scenarios
- Validate both positive and negative test cases

### Test Performance
- Keep tests fast and efficient
- Use parallel execution where appropriate
- Minimize external dependencies
- Cache test data when possible

## Testing Workflow

### Local Development
1. **Quick Test**: Run individual test files for rapid iteration
2. **Full Test**: Run complete test suite for comprehensive validation
3. **Specific Test**: Use targeted test execution for focused validation
4. **Clean Test**: Use cleanup to ensure clean test environment

### Continuous Integration
1. **Automated Testing**: Run tests on every code change
2. **Cross-Platform**: Test across different environments
3. **Artifact Collection**: Capture test outputs and reports
4. **Status Reporting**: Provide clear pass/fail indicators

### Regression Testing
- **Base Tests**: Always run to ensure core functionality remains intact
- **Progressive Testing**: Each new feature adds its tests to the regression suite
- **Full Suite Execution**: Run comprehensive testing for all changes
- **Isolated Testing**: Use specific test execution for targeted validation

## Test Maintenance

### Test Updates
- Update tests when functionality changes
- Maintain test relevance and accuracy
- Remove obsolete or redundant tests
- Refactor tests for better maintainability

### Test Documentation
- Document test purpose and scope
- Explain complex test scenarios
- Provide setup and execution instructions
- Keep test documentation current

### Test Review
- Review tests for completeness and accuracy
- Validate test coverage and effectiveness
- Ensure tests follow established patterns
- Identify opportunities for improvement
